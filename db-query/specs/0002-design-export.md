# æ•°æ®å¯¼å‡ºåŠŸèƒ½å¢å¼ºè®¾è®¡æ–‡æ¡£

## æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°äº†å¯¹æ•°æ®åº“æŸ¥è¯¢å·¥å…·å¯¼å‡ºåŠŸèƒ½çš„å…¨é¢å¢å¼ºè®¾è®¡ï¼Œæ—¨åœ¨æä¾›æ›´çµæ´»ã€æ›´è‡ªåŠ¨åŒ–çš„æ•°æ®å¯¼å‡ºèƒ½åŠ›ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œä¸€é”®å¼æ“ä½œæµç¨‹ã€‚

## èƒŒæ™¯

### å½“å‰çŠ¶æ€

#### å·²å®ç°çš„åŠŸèƒ½
1. **å‰ç«¯å¯¼å‡º**ï¼šHome.tsx ä¸­å·²å®ç° CSV å’Œ JSON å¯¼å‡º
   - CSV å¯¼å‡ºï¼šRFC 4180 å…¼å®¹ï¼Œæ­£ç¡®å¤„ç†ç‰¹æ®Šå­—ç¬¦
   - JSON å¯¼å‡ºï¼šç¾åŒ–çš„ JSON æ ¼å¼
   - å¤§æ•°æ®è­¦å‘Šï¼šè¶…è¿‡ 10,000 è¡Œæ—¶æ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†
   - æ—¶é—´æˆ³å‘½åï¼šå¯¼å‡ºæ–‡ä»¶è‡ªåŠ¨æ·»åŠ æ—¶é—´æˆ³

2. **å¯¼å‡ºä½ç½®**ï¼š
   - Home.tsx (lines 139-222)ï¼šå®Œæ•´å®ç°
   - show.tsx (line 259-260)ï¼šUI æŒ‰é’®å­˜åœ¨ä½†æœªè¿æ¥åŠŸèƒ½

#### å­˜åœ¨çš„é—®é¢˜

1. **åŠŸèƒ½åˆ†æ•£**ï¼šå¯¼å‡ºé€»è¾‘ä»…åœ¨ Home.tsx ä¸­å®ç°ï¼Œshow.tsx é¡µé¢æ— æ³•ä½¿ç”¨
2. **æ— åç«¯æ”¯æŒ**ï¼šçº¯å‰ç«¯å®ç°ï¼Œé™åˆ¶äº†ä»¥ä¸‹èƒ½åŠ›ï¼š
   - æ— æ³•å¯¼å‡ºå¤§å‹æ•°æ®é›†ï¼ˆå—æµè§ˆå™¨å†…å­˜é™åˆ¶ï¼‰
   - æ— æ³•æ”¯æŒæµå¼å¯¼å‡º
   - æ— æ³•è®°å½•å¯¼å‡ºå†å²
   - æ— æ³•æ”¯æŒå®šæ—¶å¯¼å‡º
3. **ç¼ºä¹è‡ªåŠ¨åŒ–**ï¼šæ²¡æœ‰å‘½ä»¤å¼æ¥å£ï¼Œæ— æ³•å®ç°"æŸ¥è¯¢+å¯¼å‡º"ä¸€é”®å®Œæˆ
4. **æ ¼å¼æœ‰é™**ï¼šä»…æ”¯æŒ CSV å’Œ JSONï¼Œä¸æ”¯æŒ Excelã€Parquet ç­‰æ ¼å¼
5. **æ— æ™ºèƒ½äº¤äº’**ï¼šå¯¼å‡ºåæ²¡æœ‰è‡ªç„¶è¯­è¨€æç¤ºæˆ–å»ºè®®

### éœ€æ±‚ç›®æ ‡

1. âœ… **å¤šæ ¼å¼æ”¯æŒ**ï¼šCSVã€JSONï¼ˆå·²æœ‰ï¼‰ï¼Œå¢åŠ  Excelã€SQL ç­‰æ ¼å¼
2. ğŸ¯ **è‡ªåŠ¨åŒ–æµç¨‹**ï¼šè®¾è®¡ Command åŠŸèƒ½ï¼Œå®ç°"æŸ¥è¯¢+å¯¼å‡º"ä¸€é”®å®Œæˆ
3. ğŸ¯ **æ™ºèƒ½äº¤äº’**ï¼šé€šè¿‡è‡ªç„¶è¯­è¨€è§¦å‘å¯¼å‡ºï¼ŒAI ä¸»åŠ¨è¯¢é—®å¯¼å‡ºéœ€æ±‚
4. ğŸ¯ **ç»Ÿä¸€æ¶æ„**ï¼šå‰åç«¯ååŒï¼Œæ”¯æŒå¤§æ•°æ®å¯¼å‡ºå’Œå†å²è®°å½•
5. ğŸ¯ **å¯æ‰©å±•æ€§**ï¼šéµå¾ª SOLID åŸåˆ™ï¼Œæ–¹ä¾¿æ·»åŠ æ–°çš„å¯¼å‡ºæ ¼å¼

## æ¶æ„è®¾è®¡

### è®¾è®¡æ¨¡å¼

é‡‡ç”¨ **Strategy + Command + Observer** æ¨¡å¼ç»„åˆï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     API å±‚ (FastAPI)                     â”‚
â”‚  POST /api/v1/dbs/{name}/export                         â”‚
â”‚  POST /api/v1/dbs/{name}/query-and-export (æ–°)          â”‚
â”‚  GET  /api/v1/dbs/{name}/export/history                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  ExportService   â”‚ (Facade - é—¨é¢æ¨¡å¼)
        â”‚  - export()      â”‚ â€¢ åè°ƒæŸ¥è¯¢å’Œå¯¼å‡º
        â”‚  - command()     â”‚ â€¢ ç®¡ç†å¯¼å‡ºå†å²
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â€¢ è§¦å‘é€šçŸ¥
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ExportFormatRegistry     â”‚ (Factory - å·¥å‚æ¨¡å¼)
    â”‚  - register_format()      â”‚ â€¢ ç®¡ç†å¯¼å‡ºå™¨æ³¨å†Œ
    â”‚  - get_exporter()         â”‚ â€¢ å¯¼å‡ºå™¨ç”Ÿå‘½å‘¨æœŸ
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   ExportFormat (æŠ½è±¡åŸºç±»)             â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚   â”‚ + export(data, options)        â”‚  â”‚ (Strategy - ç­–ç•¥æ¨¡å¼)
    â”‚   â”‚ + get_file_extension()         â”‚  â”‚
    â”‚   â”‚ + get_mime_type()              â”‚  â”‚
    â”‚   â”‚ + supports_streaming()         â”‚  â”‚
    â”‚   â”‚ + validate_options()           â”‚  â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼             â–¼              â–¼              â–¼              â–¼
CSVExporter  JSONExporter  ExcelExporter  SQLExporter  (å¯æ‰©å±•)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Command å±‚ (æ–°å¢)                         â”‚
â”‚  ExportCommand - å‘½ä»¤æ¨¡å¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ - execute()        â”‚ æ‰§è¡ŒæŸ¥è¯¢å¹¶å¯¼å‡º                 â”‚ â”‚
â”‚  â”‚ - undo()           â”‚ å›æ»šæ“ä½œï¼ˆåˆ é™¤å¯¼å‡ºæ–‡ä»¶ï¼‰       â”‚ â”‚
â”‚  â”‚ - get_status()     â”‚ è·å–æ‰§è¡ŒçŠ¶æ€                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            æ™ºèƒ½äº¤äº’å±‚ (NL Trigger - æ–°å¢)                â”‚
â”‚  ExportSuggestionService                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ - analyze_query_result()  â”‚ åˆ†ææŸ¥è¯¢ç»“æœ          â”‚ â”‚
â”‚  â”‚ - suggest_export()        â”‚ ç”Ÿæˆå¯¼å‡ºå»ºè®®          â”‚ â”‚
â”‚  â”‚ - parse_nl_command()      â”‚ è§£æè‡ªç„¶è¯­è¨€å‘½ä»¤      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  "éœ€è¦å°†è¿™æ¬¡çš„æŸ¥è¯¢ç»“æœå¯¼å‡ºä¸º CSV æˆ– JSON æ–‡ä»¶å—ï¼Ÿ"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

#### 1. ExportFormat (æŠ½è±¡åŸºç±»)

å®šä¹‰æ‰€æœ‰å¯¼å‡ºæ ¼å¼å¿…é¡»å®ç°çš„å¥‘çº¦ï¼š

```python
# app/export/base.py
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, BinaryIO
from enum import Enum

class ExportFormat(str, Enum):
    CSV = "csv"
    JSON = "json"
    EXCEL = "excel"
    SQL = "sql"

class ExportOptions:
    """å¯¼å‡ºé€‰é¡¹é…ç½®"""
    format: ExportFormat
    delimiter: str = ","  # CSV åˆ†éš”ç¬¦
    include_headers: bool = True
    pretty_print: bool = True  # JSON æ ¼å¼åŒ–
    sheet_name: str = "Sheet1"  # Excel å·¥ä½œè¡¨å
    compress: bool = False  # æ˜¯å¦å‹ç¼©ï¼ˆ.zipï¼‰
    max_rows: Optional[int] = None  # æœ€å¤§è¡Œæ•°é™åˆ¶

class ExportResult:
    """å¯¼å‡ºç»“æœ"""
    file_path: Optional[str]  # æœåŠ¡ç«¯å¯¼å‡ºï¼šæ–‡ä»¶è·¯å¾„
    file_data: Optional[bytes]  # å®¢æˆ·ç«¯å¯¼å‡ºï¼šäºŒè¿›åˆ¶æ•°æ®
    file_name: str
    mime_type: str
    row_count: int
    file_size_bytes: int
    export_time_ms: int

class BaseExporter(ABC):
    """å¯¼å‡ºå™¨æŠ½è±¡åŸºç±»"""

    @abstractmethod
    async def export(
        self,
        columns: List[Dict[str, str]],
        rows: List[Dict[str, Any]],
        options: ExportOptions
    ) -> ExportResult:
        """
        æ‰§è¡Œæ•°æ®å¯¼å‡º

        Args:
            columns: åˆ—å®šä¹‰ [{"name": "id", "dataType": "integer"}]
            rows: æ•°æ®è¡Œ [{"id": 1, "name": "Alice"}]
            options: å¯¼å‡ºé€‰é¡¹

        Returns:
            ExportResult: å¯¼å‡ºç»“æœ
        """
        pass

    @abstractmethod
    def get_file_extension(self) -> str:
        """è·å–æ–‡ä»¶æ‰©å±•åï¼Œå¦‚ 'csv'"""
        pass

    @abstractmethod
    def get_mime_type(self) -> str:
        """è·å– MIME ç±»å‹ï¼Œå¦‚ 'text/csv'"""
        pass

    @abstractmethod
    def supports_streaming(self) -> bool:
        """æ˜¯å¦æ”¯æŒæµå¼å¯¼å‡ºï¼ˆç”¨äºå¤§æ•°æ®é›†ï¼‰"""
        pass

    @abstractmethod
    async def stream_export(
        self,
        columns: List[Dict[str, str]],
        row_iterator: Any,  # AsyncIterator
        output: BinaryIO,
        options: ExportOptions
    ) -> int:
        """
        æµå¼å¯¼å‡ºï¼ˆç”¨äºå¤§æ•°æ®é›†ï¼‰

        Returns:
            int: å¯¼å‡ºçš„è¡Œæ•°
        """
        pass

    def validate_options(self, options: ExportOptions) -> tuple[bool, Optional[str]]:
        """
        éªŒè¯å¯¼å‡ºé€‰é¡¹

        Returns:
            (is_valid, error_message)
        """
        return True, None
```

#### 2. å…·ä½“å¯¼å‡ºå™¨å®ç°

##### CSVExporter
```python
# app/export/csv_exporter.py
import csv
import io
from typing import List, Dict, Any
from .base import BaseExporter, ExportOptions, ExportResult

class CSVExporter(BaseExporter):
    """CSV å¯¼å‡ºå™¨ - RFC 4180 å…¼å®¹"""

    async def export(
        self,
        columns: List[Dict[str, str]],
        rows: List[Dict[str, Any]],
        options: ExportOptions
    ) -> ExportResult:
        start_time = time.time()
        output = io.StringIO()

        # å†™å…¥è¡¨å¤´
        column_names = [col["name"] for col in columns]
        writer = csv.DictWriter(
            output,
            fieldnames=column_names,
            delimiter=options.delimiter,
            quoting=csv.QUOTE_MINIMAL
        )

        if options.include_headers:
            writer.writeheader()

        # å†™å…¥æ•°æ®è¡Œ
        for row in rows:
            # å¤„ç† None å€¼
            cleaned_row = {k: (v if v is not None else "") for k, v in row.items()}
            writer.writerow(cleaned_row)

        csv_content = output.getvalue()
        file_data = csv_content.encode("utf-8")

        return ExportResult(
            file_data=file_data,
            file_name=f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime_type="text/csv",
            row_count=len(rows),
            file_size_bytes=len(file_data),
            export_time_ms=int((time.time() - start_time) * 1000)
        )

    def get_file_extension(self) -> str:
        return "csv"

    def get_mime_type(self) -> str:
        return "text/csv"

    def supports_streaming(self) -> bool:
        return True

    async def stream_export(self, columns, row_iterator, output, options):
        """æµå¼ CSV å¯¼å‡ºï¼Œé€‚ç”¨äºå¤§æ•°æ®é›†"""
        column_names = [col["name"] for col in columns]
        writer = csv.DictWriter(
            output,
            fieldnames=column_names,
            delimiter=options.delimiter
        )

        if options.include_headers:
            writer.writeheader()

        row_count = 0
        async for row in row_iterator:
            cleaned_row = {k: (v if v is not None else "") for k, v in row.items()}
            writer.writerow(cleaned_row)
            row_count += 1

        return row_count
```

##### JSONExporter
```python
# app/export/json_exporter.py
import json
from .base import BaseExporter, ExportOptions, ExportResult

class JSONExporter(BaseExporter):
    """JSON å¯¼å‡ºå™¨"""

    async def export(
        self,
        columns: List[Dict[str, str]],
        rows: List[Dict[str, Any]],
        options: ExportOptions
    ) -> ExportResult:
        start_time = time.time()

        # æ„å»ºå¯¼å‡ºæ•°æ®
        export_data = {
            "columns": columns,
            "rows": rows,
            "metadata": {
                "row_count": len(rows),
                "exported_at": datetime.now().isoformat()
            }
        }

        # åºåˆ—åŒ–
        if options.pretty_print:
            json_content = json.dumps(export_data, indent=2, ensure_ascii=False)
        else:
            json_content = json.dumps(export_data, ensure_ascii=False)

        file_data = json_content.encode("utf-8")

        return ExportResult(
            file_data=file_data,
            file_name=f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime_type="application/json",
            row_count=len(rows),
            file_size_bytes=len(file_data),
            export_time_ms=int((time.time() - start_time) * 1000)
        )

    def get_file_extension(self) -> str:
        return "json"

    def get_mime_type(self) -> str:
        return "application/json"

    def supports_streaming(self) -> bool:
        return False  # JSON éœ€è¦å®Œæ•´æ•°æ®ç»“æ„
```

##### ExcelExporter (æ–°å¢)
```python
# app/export/excel_exporter.py
import io
from openpyxl import Workbook
from .base import BaseExporter, ExportOptions, ExportResult

class ExcelExporter(BaseExporter):
    """Excel å¯¼å‡ºå™¨ - ä½¿ç”¨ openpyxl"""

    async def export(
        self,
        columns: List[Dict[str, str]],
        rows: List[Dict[str, Any]],
        options: ExportOptions
    ) -> ExportResult:
        start_time = time.time()

        # åˆ›å»ºå·¥ä½œç°¿
        wb = Workbook()
        ws = wb.active
        ws.title = options.sheet_name

        # å†™å…¥è¡¨å¤´
        if options.include_headers:
            headers = [col["name"] for col in columns]
            ws.append(headers)

            # åŠ ç²—è¡¨å¤´
            for cell in ws[1]:
                cell.font = cell.font.copy(bold=True)

        # å†™å…¥æ•°æ®
        for row in rows:
            row_data = [row.get(col["name"]) for col in columns]
            ws.append(row_data)

        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                if cell.value:
                    max_length = max(max_length, len(str(cell.value)))
            ws.column_dimensions[column_letter].width = min(max_length + 2, 50)

        # ä¿å­˜åˆ°å†…å­˜
        output = io.BytesIO()
        wb.save(output)
        file_data = output.getvalue()

        return ExportResult(
            file_data=file_data,
            file_name=f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            row_count=len(rows),
            file_size_bytes=len(file_data),
            export_time_ms=int((time.time() - start_time) * 1000)
        )

    def get_file_extension(self) -> str:
        return "xlsx"

    def get_mime_type(self) -> str:
        return "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"

    def supports_streaming(self) -> bool:
        return True  # openpyxl æ”¯æŒå¢é‡å†™å…¥
```

##### SQLExporter (æ–°å¢)
```python
# app/export/sql_exporter.py
from .base import BaseExporter, ExportOptions, ExportResult

class SQLExporter(BaseExporter):
    """SQL INSERT è¯­å¥å¯¼å‡ºå™¨"""

    async def export(
        self,
        columns: List[Dict[str, str]],
        rows: List[Dict[str, Any]],
        options: ExportOptions
    ) -> ExportResult:
        start_time = time.time()

        # ç”Ÿæˆè¡¨åï¼ˆä»é€‰é¡¹ä¸­è·å–ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
        table_name = options.table_name if hasattr(options, 'table_name') else "exported_data"
        column_names = [col["name"] for col in columns]

        # æ„å»º SQL è¯­å¥
        sql_statements = []

        # æ·»åŠ æ³¨é‡Šå¤´
        sql_statements.append(f"-- Exported at {datetime.now().isoformat()}")
        sql_statements.append(f"-- Total rows: {len(rows)}")
        sql_statements.append("")

        # ç”Ÿæˆ INSERT è¯­å¥
        for row in rows:
            values = []
            for col_name in column_names:
                value = row.get(col_name)
                if value is None:
                    values.append("NULL")
                elif isinstance(value, str):
                    # è½¬ä¹‰å•å¼•å·
                    escaped_value = value.replace("'", "''")
                    values.append(f"'{escaped_value}'")
                elif isinstance(value, (int, float)):
                    values.append(str(value))
                else:
                    values.append(f"'{str(value)}'")

            columns_str = ", ".join(column_names)
            values_str = ", ".join(values)
            sql_statements.append(
                f"INSERT INTO {table_name} ({columns_str}) VALUES ({values_str});"
            )

        sql_content = "\n".join(sql_statements)
        file_data = sql_content.encode("utf-8")

        return ExportResult(
            file_data=file_data,
            file_name=f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql",
            mime_type="application/sql",
            row_count=len(rows),
            file_size_bytes=len(file_data),
            export_time_ms=int((time.time() - start_time) * 1000)
        )

    def get_file_extension(self) -> str:
        return "sql"

    def get_mime_type(self) -> str:
        return "application/sql"

    def supports_streaming(self) -> bool:
        return True
```

#### 3. ExportFormatRegistry (å·¥å‚æ¨¡å¼)

```python
# app/export/registry.py
from typing import Dict, Type
from .base import BaseExporter, ExportFormat

class ExportFormatRegistry:
    """å¯¼å‡ºæ ¼å¼æ³¨å†Œè¡¨ - å·¥å‚æ¨¡å¼"""

    def __init__(self):
        self._exporters: Dict[ExportFormat, Type[BaseExporter]] = {}

    def register(self, format: ExportFormat, exporter_class: Type[BaseExporter]):
        """æ³¨å†Œå¯¼å‡ºå™¨"""
        self._exporters[format] = exporter_class

    def get_exporter(self, format: ExportFormat) -> BaseExporter:
        """è·å–å¯¼å‡ºå™¨å®ä¾‹"""
        if format not in self._exporters:
            raise ValueError(f"Unsupported export format: {format}")

        exporter_class = self._exporters[format]
        return exporter_class()

    def list_formats(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„æ ¼å¼"""
        return list(self._exporters.keys())

# å…¨å±€æ³¨å†Œè¡¨å®ä¾‹
export_registry = ExportFormatRegistry()

# æ³¨å†Œå†…ç½®å¯¼å‡ºå™¨
from .csv_exporter import CSVExporter
from .json_exporter import JSONExporter
from .excel_exporter import ExcelExporter
from .sql_exporter import SQLExporter

export_registry.register(ExportFormat.CSV, CSVExporter)
export_registry.register(ExportFormat.JSON, JSONExporter)
export_registry.register(ExportFormat.EXCEL, ExcelExporter)
export_registry.register(ExportFormat.SQL, SQLExporter)
```

#### 4. ExportService (é—¨é¢æ¨¡å¼)

```python
# app/services/export_service.py
from typing import Optional
from ..export.base import ExportFormat, ExportOptions, ExportResult
from ..export.registry import export_registry
from ..models.query import QueryExport
from .database_service import DatabaseService

class ExportService:
    """å¯¼å‡ºæœåŠ¡é—¨é¢"""

    def __init__(self, db_service: DatabaseService):
        self.db_service = db_service

    async def export_query_result(
        self,
        columns: List[Dict[str, str]],
        rows: List[Dict[str, Any]],
        format: ExportFormat,
        options: Optional[ExportOptions] = None
    ) -> ExportResult:
        """
        å¯¼å‡ºæŸ¥è¯¢ç»“æœ

        Args:
            columns: åˆ—å®šä¹‰
            rows: æ•°æ®è¡Œ
            format: å¯¼å‡ºæ ¼å¼
            options: å¯¼å‡ºé€‰é¡¹

        Returns:
            ExportResult: å¯¼å‡ºç»“æœ
        """
        # ä½¿ç”¨é»˜è®¤é€‰é¡¹
        if options is None:
            options = ExportOptions(format=format)

        # è·å–å¯¼å‡ºå™¨
        exporter = export_registry.get_exporter(format)

        # éªŒè¯é€‰é¡¹
        is_valid, error = exporter.validate_options(options)
        if not is_valid:
            raise ValueError(f"Invalid export options: {error}")

        # æ‰§è¡Œå¯¼å‡º
        result = await exporter.export(columns, rows, options)

        return result

    async def save_export_history(
        self,
        db_name: str,
        sql: str,
        format: ExportFormat,
        result: ExportResult
    ):
        """ä¿å­˜å¯¼å‡ºå†å²åˆ°æ•°æ®åº“"""
        # TODO: å®ç°å¯¼å‡ºå†å²è®°å½•
        pass

    async def get_export_history(
        self,
        db_name: str,
        limit: int = 10
    ) -> List[QueryExport]:
        """è·å–å¯¼å‡ºå†å²"""
        # TODO: å®ç°è·å–å†å²è®°å½•
        pass
```

#### 5. ExportCommand (å‘½ä»¤æ¨¡å¼ - è‡ªåŠ¨åŒ–æµç¨‹)

```python
# app/commands/export_command.py
from typing import Optional
from enum import Enum
from pydantic import BaseModel

class CommandStatus(str, Enum):
    PENDING = "pending"
    EXECUTING = "executing"
    COMPLETED = "completed"
    FAILED = "failed"

class ExportCommand:
    """
    å¯¼å‡ºå‘½ä»¤ - å®ç°æŸ¥è¯¢+å¯¼å‡ºä¸€é”®å®Œæˆ

    ä½¿ç”¨åœºæ™¯ï¼š
    1. è‡ªåŠ¨åŒ–è„šæœ¬ï¼šå®šæ—¶æŸ¥è¯¢å¹¶å¯¼å‡º
    2. API è°ƒç”¨ï¼šä¸€æ¬¡è¯·æ±‚å®ŒæˆæŸ¥è¯¢å’Œå¯¼å‡º
    3. CLI å·¥å…·ï¼šå‘½ä»¤è¡Œä¸€é”®å¯¼å‡º
    """

    def __init__(
        self,
        db_service: DatabaseService,
        export_service: ExportService
    ):
        self.db_service = db_service
        self.export_service = export_service
        self.status = CommandStatus.PENDING
        self.error: Optional[str] = None
        self.result: Optional[ExportResult] = None

    async def execute(
        self,
        db_type: DatabaseType,
        db_name: str,
        db_url: str,
        sql: str,
        export_format: ExportFormat,
        export_options: Optional[ExportOptions] = None
    ) -> ExportResult:
        """
        æ‰§è¡ŒæŸ¥è¯¢å¹¶å¯¼å‡º

        Args:
            db_type: æ•°æ®åº“ç±»å‹
            db_name: æ•°æ®åº“åç§°
            db_url: è¿æ¥URL
            sql: SQL æŸ¥è¯¢è¯­å¥
            export_format: å¯¼å‡ºæ ¼å¼
            export_options: å¯¼å‡ºé€‰é¡¹

        Returns:
            ExportResult: å¯¼å‡ºç»“æœ

        Raises:
            Exception: æŸ¥è¯¢æˆ–å¯¼å‡ºå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        self.status = CommandStatus.EXECUTING

        try:
            # æ­¥éª¤ 1: æ‰§è¡ŒæŸ¥è¯¢
            query_result = await self.db_service.execute_query(
                db_type=db_type,
                name=db_name,
                url=db_url,
                sql=sql
            )

            # æ­¥éª¤ 2: å¯¼å‡ºç»“æœ
            export_result = await self.export_service.export_query_result(
                columns=query_result.columns,
                rows=query_result.rows,
                format=export_format,
                options=export_options
            )

            # æ­¥éª¤ 3: ä¿å­˜å†å²
            await self.export_service.save_export_history(
                db_name=db_name,
                sql=sql,
                format=export_format,
                result=export_result
            )

            self.status = CommandStatus.COMPLETED
            self.result = export_result
            return export_result

        except Exception as e:
            self.status = CommandStatus.FAILED
            self.error = str(e)
            raise

    async def undo(self):
        """å›æ»šæ“ä½œï¼ˆå¦‚æœå¯èƒ½ï¼‰"""
        # åˆ é™¤å¯¼å‡ºçš„æ–‡ä»¶
        if self.result and self.result.file_path:
            import os
            if os.path.exists(self.result.file_path):
                os.remove(self.result.file_path)

    def get_status(self) -> CommandStatus:
        """è·å–å‘½ä»¤æ‰§è¡ŒçŠ¶æ€"""
        return self.status
```

#### 6. ExportSuggestionService (æ™ºèƒ½äº¤äº’ - NL Trigger)

```python
# app/services/export_suggestion.py
from typing import Optional, List
from openai import AsyncOpenAI

class ExportSuggestion(BaseModel):
    """å¯¼å‡ºå»ºè®®"""
    should_suggest: bool  # æ˜¯å¦åº”è¯¥å»ºè®®å¯¼å‡º
    suggested_format: ExportFormat  # å»ºè®®çš„å¯¼å‡ºæ ¼å¼
    reason: str  # å»ºè®®åŸå› 
    prompt_text: str  # ç»™ç”¨æˆ·çš„æç¤ºæ–‡æœ¬

class ExportSuggestionService:
    """
    å¯¼å‡ºå»ºè®®æœåŠ¡ - æ™ºèƒ½åˆ†ææŸ¥è¯¢ç»“æœå¹¶æä¾›å¯¼å‡ºå»ºè®®

    ä½¿ç”¨åœºæ™¯ï¼š
    1. æŸ¥è¯¢å®Œæˆåï¼ŒAI åˆ†æç»“æœç‰¹å¾å¹¶ä¸»åŠ¨è¯¢é—®æ˜¯å¦å¯¼å‡º
    2. è§£æç”¨æˆ·çš„è‡ªç„¶è¯­è¨€å‘½ä»¤ï¼ˆ"å¯¼å‡ºä¸ºCSV"ï¼‰
    3. æ ¹æ®æ•°æ®ç‰¹å¾æ¨èæœ€ä½³å¯¼å‡ºæ ¼å¼
    """

    def __init__(self, openai_client: AsyncOpenAI):
        self.client = openai_client

    async def analyze_query_result(
        self,
        sql: str,
        row_count: int,
        columns: List[Dict[str, str]]
    ) -> ExportSuggestion:
        """
        åˆ†ææŸ¥è¯¢ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦åº”è¯¥å»ºè®®å¯¼å‡º

        è§„åˆ™ï¼š
        - è¶…è¿‡ 100 è¡Œï¼šå»ºè®®å¯¼å‡º
        - åŒ…å«èšåˆå‡½æ•°ï¼ˆSUM, AVG, COUNTï¼‰ï¼šå»ºè®®å¯¼å‡ºä¸º Excelï¼ˆä¾¿äºè¿›ä¸€æ­¥åˆ†æï¼‰
        - ç®€å• SELECTï¼šå»ºè®® CSV
        - å¤æ‚åµŒå¥—æŸ¥è¯¢ï¼šå»ºè®® JSON
        """
        should_suggest = False
        suggested_format = ExportFormat.CSV
        reason = ""

        # è§„åˆ™ 1: è¡Œæ•°åˆ¤æ–­
        if row_count >= 100:
            should_suggest = True
            reason = f"æŸ¥è¯¢è¿”å›äº† {row_count} è¡Œæ•°æ®ï¼Œå»ºè®®å¯¼å‡ºä»¥ä¾¿è¿›ä¸€æ­¥åˆ†æ"

        # è§„åˆ™ 2: SQL åˆ†æ
        sql_upper = sql.upper()
        if any(agg in sql_upper for agg in ["SUM(", "AVG(", "COUNT(", "GROUP BY"]):
            suggested_format = ExportFormat.EXCEL
            reason += "ã€‚æ£€æµ‹åˆ°èšåˆå‡½æ•°ï¼ŒExcel æ ¼å¼æ›´é€‚åˆæ•°æ®åˆ†æ"
        elif "JOIN" in sql_upper or sql_upper.count("SELECT") > 1:
            suggested_format = ExportFormat.JSON
            reason += "ã€‚æ£€æµ‹åˆ°å¤æ‚æŸ¥è¯¢ï¼ŒJSON æ ¼å¼ä¿ç•™æ•°æ®ç»“æ„"

        # è§„åˆ™ 3: åˆ—æ•°åˆ¤æ–­
        if len(columns) > 10:
            should_suggest = True
            suggested_format = ExportFormat.EXCEL
            reason += f"ã€‚æŸ¥è¯¢åŒ…å« {len(columns)} åˆ—ï¼ŒExcel ä¾¿äºæŸ¥çœ‹"

        # ç”Ÿæˆæç¤ºæ–‡æœ¬
        if should_suggest:
            format_name = {
                ExportFormat.CSV: "CSV",
                ExportFormat.JSON: "JSON",
                ExportFormat.EXCEL: "Excel",
                ExportFormat.SQL: "SQL"
            }[suggested_format]

            prompt_text = f"éœ€è¦å°†è¿™æ¬¡çš„æŸ¥è¯¢ç»“æœå¯¼å‡ºä¸º {format_name} æ–‡ä»¶å—ï¼Ÿ{reason}"
        else:
            prompt_text = ""

        return ExportSuggestion(
            should_suggest=should_suggest,
            suggested_format=suggested_format,
            reason=reason,
            prompt_text=prompt_text
        )

    async def parse_nl_export_command(self, user_input: str) -> Optional[Dict]:
        """
        è§£æè‡ªç„¶è¯­è¨€å¯¼å‡ºå‘½ä»¤

        ç¤ºä¾‹è¾“å…¥ï¼š
        - "å¯¼å‡ºä¸º CSV"
        - "æŠŠè¿™ä¸ªç»“æœä¿å­˜æˆ Excel"
        - "å¯¼å‡ºä¸Šæ¬¡æŸ¥è¯¢çš„ç»“æœä¸º JSON"

        Returns:
            {
                "action": "export",
                "format": "csv",
                "target": "current" | "last"
            }
            æˆ– Noneï¼ˆå¦‚æœä¸æ˜¯å¯¼å‡ºå‘½ä»¤ï¼‰
        """
        # ä½¿ç”¨ OpenAI è§£æè‡ªç„¶è¯­è¨€
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªå¯¼å‡ºå‘½ä»¤è§£æåŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç”¨è‡ªç„¶è¯­è¨€æè¿°å¯¼å‡ºéœ€æ±‚ï¼Œä½ éœ€è¦è§£æå‡ºï¼š
        1. action: å¿…é¡»æ˜¯ "export"
        2. format: å¯¼å‡ºæ ¼å¼ï¼ˆcsv/json/excel/sqlï¼‰
        3. target: ç›®æ ‡ï¼ˆcurrent=å½“å‰ç»“æœï¼Œlast=ä¸Šæ¬¡ç»“æœï¼‰

        å¦‚æœç”¨æˆ·è¾“å…¥ä¸æ˜¯å¯¼å‡ºå‘½ä»¤ï¼Œè¿”å› nullã€‚

        ç¤ºä¾‹ï¼š
        è¾“å…¥: "å¯¼å‡ºä¸ºCSV"
        è¾“å‡º: {"action": "export", "format": "csv", "target": "current"}

        è¾“å…¥: "æŠŠä¸Šæ¬¡çš„æŸ¥è¯¢ä¿å­˜æˆExcel"
        è¾“å‡º: {"action": "export", "format": "excel", "target": "last"}

        è¾“å…¥: "æŸ¥è¯¢ç”¨æˆ·è¡¨"
        è¾“å‡º: null
        """

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                response_format={"type": "json_object"}
            )

            result = json.loads(response.choices[0].message.content)
            return result if result.get("action") == "export" else None

        except Exception as e:
            # è§£æå¤±è´¥ï¼Œè¿”å› None
            return None
```

### æ•°æ®æ¨¡å‹

```python
# app/models/export.py
from sqlmodel import SQLModel, Field
from datetime import datetime
from typing import Optional

class QueryExport(SQLModel, table=True):
    """æŸ¥è¯¢å¯¼å‡ºå†å²è®°å½•"""
    __tablename__ = "query_exports"

    id: Optional[int] = Field(default=None, primary_key=True)

    # å…³è”ä¿¡æ¯
    database_name: str = Field(index=True)
    sql: str  # æ‰§è¡Œçš„ SQL

    # å¯¼å‡ºä¿¡æ¯
    export_format: str  # csv/json/excel/sql
    file_name: str
    file_path: Optional[str]  # æœåŠ¡ç«¯æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¿å­˜ï¼‰
    file_size_bytes: int

    # ç»Ÿè®¡ä¿¡æ¯
    row_count: int
    export_time_ms: int

    # æ—¶é—´æˆ³
    created_at: datetime = Field(default_factory=datetime.utcnow)

    # å…ƒæ•°æ®
    user_id: Optional[str] = None  # æœªæ¥æ”¯æŒå¤šç”¨æˆ·
```

### API ç«¯ç‚¹è®¾è®¡

#### 1. å¯¼å‡ºæŸ¥è¯¢ç»“æœ

```python
# POST /api/v1/dbs/{name}/export
@router.post("/{name}/export")
async def export_query_result(
    name: str,
    request: ExportRequest
) -> Response:
    """
    å¯¼å‡ºå·²æ‰§è¡Œçš„æŸ¥è¯¢ç»“æœ

    Request Body:
    {
        "columns": [{"name": "id", "dataType": "integer"}],
        "rows": [{"id": 1, "name": "Alice"}],
        "format": "csv",  // csv | json | excel | sql
        "options": {
            "delimiter": ",",
            "include_headers": true,
            "pretty_print": true
        }
    }

    Response:
    - Content-Type: æ ¹æ®æ ¼å¼è®¾ç½®ï¼ˆtext/csv, application/json ç­‰ï¼‰
    - Content-Disposition: attachment; filename="export_20240101_120000.csv"
    - æ–‡ä»¶äºŒè¿›åˆ¶æ•°æ®
    """
    # è·å–å¯¼å‡ºæœåŠ¡
    result = await export_service.export_query_result(
        columns=request.columns,
        rows=request.rows,
        format=request.format,
        options=request.options
    )

    # è¿”å›æ–‡ä»¶
    return Response(
        content=result.file_data,
        media_type=result.mime_type,
        headers={
            "Content-Disposition": f'attachment; filename="{result.file_name}"'
        }
    )
```

#### 2. æŸ¥è¯¢å¹¶å¯¼å‡ºï¼ˆCommand æ¥å£ï¼‰

```python
# POST /api/v1/dbs/{name}/query-and-export
@router.post("/{name}/query-and-export")
async def query_and_export(
    name: str,
    request: QueryAndExportRequest
) -> Response:
    """
    ä¸€é”®å®ŒæˆæŸ¥è¯¢å’Œå¯¼å‡º

    Request Body:
    {
        "sql": "SELECT * FROM users LIMIT 1000",
        "format": "csv",
        "options": {
            "delimiter": ",",
            "include_headers": true
        }
    }

    Response:
    - ç›´æ¥è¿”å›å¯¼å‡ºçš„æ–‡ä»¶

    ä½¿ç”¨åœºæ™¯ï¼š
    - è‡ªåŠ¨åŒ–è„šæœ¬
    - å®šæ—¶ä»»åŠ¡
    - CLI å·¥å…·
    """
    # è·å–æ•°æ®åº“è¿æ¥
    db = await database_service.get_database(name)

    # åˆ›å»ºå¯¼å‡ºå‘½ä»¤
    command = ExportCommand(database_service, export_service)

    # æ‰§è¡Œå‘½ä»¤
    result = await command.execute(
        db_type=db.dbType,
        db_name=name,
        db_url=db.url,
        sql=request.sql,
        export_format=request.format,
        export_options=request.options
    )

    # è¿”å›æ–‡ä»¶
    return Response(
        content=result.file_data,
        media_type=result.mime_type,
        headers={
            "Content-Disposition": f'attachment; filename="{result.file_name}"'
        }
    )
```

#### 3. å¯¼å‡ºå†å²

```python
# GET /api/v1/dbs/{name}/exports
@router.get("/{name}/exports")
async def get_export_history(
    name: str,
    limit: int = 10
) -> List[QueryExport]:
    """
    è·å–å¯¼å‡ºå†å²è®°å½•

    Response:
    [
        {
            "id": 1,
            "database_name": "mydb",
            "sql": "SELECT * FROM users",
            "export_format": "csv",
            "file_name": "export_20240101_120000.csv",
            "file_size_bytes": 1024,
            "row_count": 100,
            "export_time_ms": 150,
            "created_at": "2024-01-01T12:00:00Z"
        }
    ]
    """
    return await export_service.get_export_history(name, limit)
```

#### 4. å¯¼å‡ºå»ºè®®ï¼ˆAI é©±åŠ¨ï¼‰

```python
# POST /api/v1/dbs/{name}/export/suggest
@router.post("/{name}/export/suggest")
async def suggest_export(
    name: str,
    request: QueryResult
) -> ExportSuggestion:
    """
    åˆ†ææŸ¥è¯¢ç»“æœå¹¶æä¾›å¯¼å‡ºå»ºè®®

    Request Body:
    {
        "sql": "SELECT * FROM users WHERE...",
        "columns": [...],
        "rowCount": 500
    }

    Response:
    {
        "should_suggest": true,
        "suggested_format": "excel",
        "reason": "æŸ¥è¯¢è¿”å›äº†500è¡Œæ•°æ®ï¼Œæ£€æµ‹åˆ°èšåˆå‡½æ•°",
        "prompt_text": "éœ€è¦å°†è¿™æ¬¡çš„æŸ¥è¯¢ç»“æœå¯¼å‡ºä¸º Excel æ–‡ä»¶å—ï¼Ÿ..."
    }
    """
    suggestion = await export_suggestion_service.analyze_query_result(
        sql=request.sql,
        row_count=request.rowCount,
        columns=request.columns
    )

    return suggestion
```

#### 5. è§£æè‡ªç„¶è¯­è¨€å¯¼å‡ºå‘½ä»¤

```python
# POST /api/v1/export/parse-nl
@router.post("/export/parse-nl")
async def parse_nl_export_command(
    request: NLCommandRequest
) -> Optional[Dict]:
    """
    è§£æè‡ªç„¶è¯­è¨€å¯¼å‡ºå‘½ä»¤

    Request Body:
    {
        "input": "å¯¼å‡ºä¸ºCSV"
    }

    Response:
    {
        "action": "export",
        "format": "csv",
        "target": "current"
    }
    æˆ– nullï¼ˆå¦‚æœä¸æ˜¯å¯¼å‡ºå‘½ä»¤ï¼‰
    """
    result = await export_suggestion_service.parse_nl_export_command(
        request.input
    )

    return result
```

### å‰ç«¯é›†æˆ

#### 1. ç»Ÿä¸€å¯¼å‡ºæœåŠ¡

```typescript
// frontend/src/services/exportService.ts
import { apiClient } from "./api";

export interface ExportOptions {
  format: "csv" | "json" | "excel" | "sql";
  delimiter?: string;
  includeHeaders?: boolean;
  prettyPrint?: boolean;
  sheetName?: string;
}

export interface ExportSuggestion {
  shouldSuggest: boolean;
  suggestedFormat: string;
  reason: string;
  promptText: string;
}

export class ExportService {
  /**
   * å¯¼å‡ºæŸ¥è¯¢ç»“æœï¼ˆå®¢æˆ·ç«¯å¯¼å‡º - å½“å‰å®ç°ï¼‰
   */
  static exportClientSide(
    columns: Array<{ name: string; dataType: string }>,
    rows: Array<Record<string, any>>,
    format: "csv" | "json",
    dbName: string
  ) {
    if (format === "csv") {
      this.exportToCSV(columns, rows, dbName);
    } else if (format === "json") {
      this.exportToJSON(rows, dbName);
    }
  }

  /**
   * å¯¼å‡ºæŸ¥è¯¢ç»“æœï¼ˆæœåŠ¡ç«¯å¯¼å‡º - æ–°å®ç°ï¼‰
   */
  static async exportServerSide(
    columns: Array<{ name: string; dataType: string }>,
    rows: Array<Record<string, any>>,
    format: "csv" | "json" | "excel" | "sql",
    dbName: string,
    options?: Partial<ExportOptions>
  ): Promise<void> {
    try {
      const response = await apiClient.post(
        `/api/v1/dbs/${dbName}/export`,
        {
          columns,
          rows,
          format,
          options: {
            delimiter: ",",
            includeHeaders: true,
            prettyPrint: true,
            ...options,
          },
        },
        {
          responseType: "blob", // é‡è¦ï¼šæ¥æ”¶äºŒè¿›åˆ¶æ•°æ®
        }
      );

      // ä»å“åº”å¤´è·å–æ–‡ä»¶å
      const contentDisposition = response.headers["content-disposition"];
      const fileNameMatch = contentDisposition?.match(/filename="(.+)"/);
      const fileName = fileNameMatch ? fileNameMatch[1] : `export.${format}`;

      // è§¦å‘ä¸‹è½½
      const blob = new Blob([response.data]);
      const url = URL.createObjectURL(blob);
      const link = document.createElement("a");
      link.href = url;
      link.download = fileName;
      link.click();
      URL.revokeObjectURL(url);
    } catch (error) {
      console.error("Export failed:", error);
      throw error;
    }
  }

  /**
   * ä¸€é”®æŸ¥è¯¢å¹¶å¯¼å‡º
   */
  static async queryAndExport(
    dbName: string,
    sql: string,
    format: "csv" | "json" | "excel" | "sql",
    options?: Partial<ExportOptions>
  ): Promise<void> {
    try {
      const response = await apiClient.post(
        `/api/v1/dbs/${dbName}/query-and-export`,
        {
          sql,
          format,
          options: {
            delimiter: ",",
            includeHeaders: true,
            ...options,
          },
        },
        {
          responseType: "blob",
        }
      );

      // è§¦å‘ä¸‹è½½
      const contentDisposition = response.headers["content-disposition"];
      const fileNameMatch = contentDisposition?.match(/filename="(.+)"/);
      const fileName = fileNameMatch ? fileNameMatch[1] : `export.${format}`;

      const blob = new Blob([response.data]);
      const url = URL.createObjectURL(blob);
      const link = document.createElement("a");
      link.href = url;
      link.download = fileName;
      link.click();
      URL.revokeObjectURL(url);
    } catch (error) {
      console.error("Query and export failed:", error);
      throw error;
    }
  }

  /**
   * è·å–å¯¼å‡ºå»ºè®®
   */
  static async getExportSuggestion(
    dbName: string,
    sql: string,
    columns: Array<{ name: string; dataType: string }>,
    rowCount: number
  ): Promise<ExportSuggestion> {
    const response = await apiClient.post(`/api/v1/dbs/${dbName}/export/suggest`, {
      sql,
      columns,
      rowCount,
    });
    return response.data;
  }

  /**
   * è§£æè‡ªç„¶è¯­è¨€å¯¼å‡ºå‘½ä»¤
   */
  static async parseNLCommand(input: string): Promise<any> {
    const response = await apiClient.post("/api/v1/export/parse-nl", {
      input,
    });
    return response.data;
  }

  // ç§æœ‰æ–¹æ³•ï¼šå®¢æˆ·ç«¯ CSV å¯¼å‡º
  private static exportToCSV(
    columns: Array<{ name: string; dataType: string }>,
    rows: Array<Record<string, any>>,
    dbName: string
  ) {
    const headers = columns.map((col) => col.name);
    const csvRows = [headers.join(",")];

    rows.forEach((row) => {
      const values = headers.map((header) => {
        const value = row[header];
        if (value === null || value === undefined) return "";
        const stringValue = String(value);
        if (
          stringValue.includes(",") ||
          stringValue.includes('"') ||
          stringValue.includes("\n")
        ) {
          return `"${stringValue.replace(/"/g, '""')}"`;
        }
        return stringValue;
      });
      csvRows.push(values.join(","));
    });

    const csvContent = csvRows.join("\n");
    const blob = new Blob([csvContent], { type: "text/csv;charset=utf-8;" });
    const link = document.createElement("a");
    const timestamp = new Date().toISOString().replace(/[:.]/g, "-").slice(0, -5);
    link.href = URL.createObjectURL(blob);
    link.download = `${dbName}_${timestamp}.csv`;
    link.click();
    URL.revokeObjectURL(link.href);
  }

  // ç§æœ‰æ–¹æ³•ï¼šå®¢æˆ·ç«¯ JSON å¯¼å‡º
  private static exportToJSON(rows: Array<Record<string, any>>, dbName: string) {
    const jsonContent = JSON.stringify(rows, null, 2);
    const blob = new Blob([jsonContent], {
      type: "application/json;charset=utf-8;",
    });
    const link = document.createElement("a");
    const timestamp = new Date().toISOString().replace(/[:.]/g, "-").slice(0, -5);
    link.href = URL.createObjectURL(blob);
    link.download = `${dbName}_${timestamp}.json`;
    link.click();
    URL.revokeObjectURL(link.href);
  }
}
```

#### 2. å¯¼å‡ºå»ºè®®ç»„ä»¶

```typescript
// frontend/src/components/ExportSuggestion.tsx
import React, { useEffect, useState } from "react";
import { Modal, Button, Space, Radio, message } from "antd";
import { DownloadOutlined } from "@ant-design/icons";
import { ExportService, ExportSuggestion as ExportSuggestionType } from "../services/exportService";

interface Props {
  visible: boolean;
  onClose: () => void;
  dbName: string;
  sql: string;
  columns: Array<{ name: string; dataType: string }>;
  rows: Array<Record<string, any>>;
  rowCount: number;
}

export const ExportSuggestionModal: React.FC<Props> = ({
  visible,
  onClose,
  dbName,
  sql,
  columns,
  rows,
  rowCount,
}) => {
  const [suggestion, setSuggestion] = useState<ExportSuggestionType | null>(null);
  const [selectedFormat, setSelectedFormat] = useState<string>("csv");
  const [exporting, setExporting] = useState(false);

  useEffect(() => {
    if (visible) {
      loadSuggestion();
    }
  }, [visible]);

  const loadSuggestion = async () => {
    try {
      const result = await ExportService.getExportSuggestion(
        dbName,
        sql,
        columns,
        rowCount
      );
      setSuggestion(result);
      setSelectedFormat(result.suggestedFormat);
    } catch (error) {
      console.error("Failed to get export suggestion:", error);
    }
  };

  const handleExport = async () => {
    setExporting(true);
    try {
      await ExportService.exportServerSide(
        columns,
        rows,
        selectedFormat as any,
        dbName
      );
      message.success(`æˆåŠŸå¯¼å‡º ${rowCount} è¡Œæ•°æ®ä¸º ${selectedFormat.toUpperCase()}`);
      onClose();
    } catch (error) {
      message.error("å¯¼å‡ºå¤±è´¥");
    } finally {
      setExporting(false);
    }
  };

  if (!suggestion) return null;

  return (
    <Modal
      open={visible}
      onCancel={onClose}
      title={
        <Space>
          <DownloadOutlined />
          <span>å¯¼å‡ºæŸ¥è¯¢ç»“æœ</span>
        </Space>
      }
      footer={
        <Space>
          <Button onClick={onClose}>å–æ¶ˆ</Button>
          <Button type="primary" onClick={handleExport} loading={exporting}>
            å¯¼å‡º
          </Button>
        </Space>
      }
    >
      <Space direction="vertical" style={{ width: "100%" }} size="large">
        <div>
          <p>{suggestion.promptText}</p>
          {suggestion.reason && (
            <p style={{ color: "#666", fontSize: 13 }}>
              {suggestion.reason}
            </p>
          )}
        </div>

        <Radio.Group
          value={selectedFormat}
          onChange={(e) => setSelectedFormat(e.target.value)}
        >
          <Space direction="vertical">
            <Radio value="csv">CSV - é€šç”¨è¡¨æ ¼æ ¼å¼</Radio>
            <Radio value="json">JSON - ç¨‹åºå¯è¯»æ ¼å¼</Radio>
            <Radio value="excel">Excel - æ•°æ®åˆ†ææ ¼å¼</Radio>
            <Radio value="sql">SQL - INSERT è¯­å¥</Radio>
          </Space>
        </Radio.Group>

        <div style={{ fontSize: 12, color: "#999" }}>
          å°†å¯¼å‡º {rowCount.toLocaleString()} è¡Œæ•°æ®
        </div>
      </Space>
    </Modal>
  );
};
```

#### 3. æ›´æ–° Home.tsx é›†æˆå¯¼å‡ºå»ºè®®

```typescript
// frontend/src/pages/Home.tsx ä¸­çš„ä¿®æ”¹

// 1. æ·»åŠ çŠ¶æ€
const [exportSuggestionVisible, setExportSuggestionVisible] = useState(false);

// 2. ä¿®æ”¹ handleExecuteQuery å‡½æ•°
const handleExecuteQuery = async () => {
  if (!selectedDatabase || !sql.trim()) {
    message.warning("Please enter a SQL query");
    return;
  }

  setExecuting(true);
  try {
    const response = await apiClient.post<QueryResult>(
      `/api/v1/dbs/${selectedDatabase}/query`,
      { sql: sql.trim() }
    );
    setQueryResult(response.data);
    message.success(
      `Query executed - ${response.data.rowCount} rows in ${response.data.executionTimeMs}ms`
    );

    // æ–°å¢ï¼šè‡ªåŠ¨æ˜¾ç¤ºå¯¼å‡ºå»ºè®®
    if (response.data.rowCount >= 50) {
      // é˜ˆå€¼å¯é…ç½®
      setTimeout(() => {
        setExportSuggestionVisible(true);
      }, 500);
    }
  } catch (error: any) {
    message.error(error.response?.data?.detail || "Query execution failed");
    setQueryResult(null);
  } finally {
    setExecuting(false);
  }
};

// 3. åœ¨ return ä¸­æ·»åŠ ç»„ä»¶
return (
  <div>
    {/* ç°æœ‰å†…å®¹ */}

    {/* å¯¼å‡ºå»ºè®® Modal */}
    {queryResult && (
      <ExportSuggestionModal
        visible={exportSuggestionVisible}
        onClose={() => setExportSuggestionVisible(false)}
        dbName={selectedDatabase!}
        sql={queryResult.sql}
        columns={queryResult.columns}
        rows={queryResult.rows}
        rowCount={queryResult.rowCount}
      />
    )}
  </div>
);
```

#### 4. æ›´æ–°å¯¼å‡ºæŒ‰é’®ä½¿ç”¨æœåŠ¡ç«¯å¯¼å‡º

```typescript
// å°† Home.tsx å’Œ show.tsx ä¸­çš„å¯¼å‡ºæŒ‰é’®ä¿®æ”¹ä¸ºï¼š

const handleExportCSV = async () => {
  if (!queryResult || queryResult.rows.length === 0) {
    message.warning("No data to export");
    return;
  }

  // é€‰æ‹©å¯¼å‡ºæ–¹å¼ï¼šå°æ•°æ®é›†ç”¨å®¢æˆ·ç«¯ï¼Œå¤§æ•°æ®é›†ç”¨æœåŠ¡ç«¯
  if (queryResult.rows.length > 10000) {
    // æœåŠ¡ç«¯å¯¼å‡ºï¼ˆæ”¯æŒå¤§æ•°æ®é›†ï¼‰
    try {
      await ExportService.exportServerSide(
        queryResult.columns,
        queryResult.rows,
        "csv",
        selectedDatabase!
      );
      message.success(`Exported ${queryResult.rowCount} rows to CSV`);
    } catch (error) {
      message.error("Export failed");
    }
  } else {
    // å®¢æˆ·ç«¯å¯¼å‡ºï¼ˆæ›´å¿«ï¼‰
    ExportService.exportClientSide(
      queryResult.columns,
      queryResult.rows,
      "csv",
      selectedDatabase!
    );
    message.success(`Exported ${queryResult.rowCount} rows to CSV`);
  }
};

// Excel å¯¼å‡ºï¼ˆä»…æœåŠ¡ç«¯ï¼‰
const handleExportExcel = async () => {
  if (!queryResult || queryResult.rows.length === 0) {
    message.warning("No data to export");
    return;
  }

  try {
    await ExportService.exportServerSide(
      queryResult.columns,
      queryResult.rows,
      "excel",
      selectedDatabase!
    );
    message.success(`Exported ${queryResult.rowCount} rows to Excel`);
  } catch (error) {
    message.error("Export failed");
  }
};
```

## æ–‡ä»¶ç»“æ„å˜åŒ–

### æ–°å¢æ–‡ä»¶

```
backend/app/
â”œâ”€â”€ export/                        # å¯¼å‡ºæ¨¡å—ï¼ˆæ–°å¢ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                    # æŠ½è±¡åŸºç±»å’Œæ•°æ®ç»“æ„
â”‚   â”œâ”€â”€ csv_exporter.py            # CSV å¯¼å‡ºå™¨
â”‚   â”œâ”€â”€ json_exporter.py           # JSON å¯¼å‡ºå™¨
â”‚   â”œâ”€â”€ excel_exporter.py          # Excel å¯¼å‡ºå™¨ï¼ˆæ–°ï¼‰
â”‚   â”œâ”€â”€ sql_exporter.py            # SQL å¯¼å‡ºå™¨ï¼ˆæ–°ï¼‰
â”‚   â”œâ”€â”€ registry.py                # å¯¼å‡ºæ ¼å¼æ³¨å†Œè¡¨
â”‚   â””â”€â”€ README.md                  # å¼€å‘è€…æŒ‡å—
â”‚
â”œâ”€â”€ commands/                      # å‘½ä»¤æ¨¡å—ï¼ˆæ–°å¢ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ export_command.py          # å¯¼å‡ºå‘½ä»¤ï¼ˆæŸ¥è¯¢+å¯¼å‡ºä¸€é”®å®Œæˆï¼‰
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ export_service.py          # å¯¼å‡ºæœåŠ¡é—¨é¢ï¼ˆæ–°å¢ï¼‰
â”‚   â””â”€â”€ export_suggestion.py       # å¯¼å‡ºå»ºè®®æœåŠ¡ï¼ˆæ–°å¢ï¼‰
â”‚
â””â”€â”€ models/
    â””â”€â”€ export.py                  # å¯¼å‡ºå†å²æ¨¡å‹ï¼ˆæ–°å¢ï¼‰

frontend/src/
â”œâ”€â”€ services/
â”‚   â””â”€â”€ exportService.ts           # ç»Ÿä¸€å¯¼å‡ºæœåŠ¡ï¼ˆæ–°å¢ï¼‰
â”‚
â””â”€â”€ components/
    â””â”€â”€ ExportSuggestion.tsx       # å¯¼å‡ºå»ºè®®ç»„ä»¶ï¼ˆæ–°å¢ï¼‰
```

### æ›´æ–°æ–‡ä»¶

```
backend/app/
â”œâ”€â”€ api/v1/
â”‚   â””â”€â”€ databases.py               # æ·»åŠ å¯¼å‡ºç›¸å…³ç«¯ç‚¹
â”‚
â””â”€â”€ alembic/versions/
    â””â”€â”€ xxxx_add_export_history.py # æ•°æ®åº“è¿ç§»ï¼šæ·»åŠ  query_exports è¡¨

frontend/src/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ Home.tsx                   # é›†æˆå¯¼å‡ºå»ºè®®å’Œæ–°æœåŠ¡
â”‚   â””â”€â”€ databases/show.tsx         # è¿æ¥å¯¼å‡ºæŒ‰é’®åŠŸèƒ½
â”‚
â””â”€â”€ types/
    â””â”€â”€ export.ts                  # å¯¼å‡ºç›¸å…³ç±»å‹å®šä¹‰ï¼ˆæ–°å¢ï¼‰
```

### ä¾èµ–æ›´æ–°

```toml
# backend/pyproject.toml - æ–°å¢ä¾èµ–
[tool.poetry.dependencies]
openpyxl = "^3.1.2"        # Excel å¯¼å‡ºæ”¯æŒ
xlsxwriter = "^3.2.0"      # å¯é€‰ï¼šExcel å†™å…¥ï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
```

```json
// frontend/package.json - å¯é€‰ä¾èµ–
{
  "dependencies": {
    "xlsx": "^0.18.5"      // å¯é€‰ï¼šå®¢æˆ·ç«¯ Excel å¯¼å‡º
  }
}
```

## SOLID åŸåˆ™éµå¾ª

### 1. å•ä¸€èŒè´£åŸåˆ™ (SRP)

- **ExportFormatï¼ˆåŸºç±»ï¼‰**: ä»…è´Ÿè´£å®šä¹‰å¯¼å‡ºæ¥å£
- **å…·ä½“å¯¼å‡ºå™¨**: æ¯ä¸ªå¯¼å‡ºå™¨ä»…è´Ÿè´£ä¸€ç§æ ¼å¼çš„å¯¼å‡º
- **ExportService**: ä»…è´Ÿè´£åè°ƒå¯¼å‡ºæµç¨‹
- **ExportCommand**: ä»…è´Ÿè´£æŸ¥è¯¢+å¯¼å‡ºå‘½ä»¤æ‰§è¡Œ
- **ExportSuggestionService**: ä»…è´Ÿè´£å¯¼å‡ºå»ºè®®å’ŒNLè§£æ

### 2. å¼€é—­åŸåˆ™ (OCP)

**å¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å…³é—­**

æ·»åŠ æ–°çš„å¯¼å‡ºæ ¼å¼ï¼ˆå¦‚ Parquetï¼‰ï¼š

```python
# 1. åˆ›å»ºæ–°å¯¼å‡ºå™¨ï¼ˆæ–°æ–‡ä»¶ï¼Œä¸ä¿®æ”¹ç°æœ‰ä»£ç ï¼‰
class ParquetExporter(BaseExporter):
    async def export(self, columns, rows, options):
        # å®ç° Parquet å¯¼å‡ºé€»è¾‘
        pass

    def get_file_extension(self) -> str:
        return "parquet"

    # å®ç°å…¶ä»–æŠ½è±¡æ–¹æ³•...

# 2. æ³¨å†Œï¼ˆæ·»åŠ 2è¡Œï¼‰
from .parquet_exporter import ParquetExporter
export_registry.register(ExportFormat.PARQUET, ParquetExporter)

# å®Œæˆï¼æ‰€æœ‰ç°æœ‰ä»£ç è‡ªåŠ¨æ”¯æŒ Parquet
```

### 3. é‡Œæ°æ›¿æ¢åŸåˆ™ (LSP)

æ‰€æœ‰å¯¼å‡ºå™¨å¯äº’æ¢ä½¿ç”¨ï¼š

```python
def export_data(exporter: BaseExporter, data):
    # é€‚ç”¨äº CSV, JSON, Excel, SQL ç­‰ä»»ä½•å¯¼å‡ºå™¨
    result = await exporter.export(data.columns, data.rows, options)
```

### 4. æ¥å£éš”ç¦»åŸåˆ™ (ISP)

BaseExporter æ¥å£ä¸“æ³¨ä¸”ç²¾ç®€ï¼š
- æ ¸å¿ƒæ–¹æ³•ï¼š`export()` - å¿…é¡»å®ç°
- å…ƒæ•°æ®æ–¹æ³•ï¼š`get_file_extension()`, `get_mime_type()`
- å¯é€‰ç‰¹æ€§ï¼š`supports_streaming()`, `stream_export()` - ä»…åœ¨éœ€è¦æ—¶å®ç°

### 5. ä¾èµ–å€’ç½®åŸåˆ™ (DIP)

ä¾èµ–æŠ½è±¡è€Œä¸æ˜¯å…·ä½“å®ç°ï¼š

```python
class ExportService:
    def __init__(self, registry: ExportFormatRegistry):
        self.registry = registry  # ä¾èµ–æŠ½è±¡æ³¨å†Œè¡¨

    async def export_query_result(self, format: ExportFormat, ...):
        # é€šè¿‡æ³¨å†Œè¡¨è·å–å¯¼å‡ºå™¨ï¼Œä¸ç›´æ¥ä¾èµ–å…·ä½“ç±»
        exporter = self.registry.get_exporter(format)
```

## ä¼˜åŠ¿å¯¹æ¯”

### æ·»åŠ æ–°å¯¼å‡ºæ ¼å¼

**ä¹‹å‰ï¼ˆå‡è®¾æ²¡æœ‰æ¶æ„ï¼‰**:
- ä¿®æ”¹å¤šä¸ªæ–‡ä»¶ï¼ˆAPIã€Serviceã€å‰ç«¯ç»„ä»¶ï¼‰
- æ·»åŠ  if-else åˆ†æ”¯åˆ¤æ–­æ ¼å¼
- 200+ è¡Œæ–°ä»£ç 
- 1å¤©å·¥ä½œé‡
- é«˜é£é™©ï¼ˆå¯èƒ½ç ´åç°æœ‰æ ¼å¼ï¼‰

**ä¹‹åï¼ˆä½¿ç”¨æ–°æ¶æ„ï¼‰**:
- 1ä¸ªæ–°æ–‡ä»¶ï¼ˆexporterï¼‰
- 2è¡Œæ³¨å†Œä»£ç 
- 150è¡Œæ–°ä»£ç 
- 4å°æ—¶å·¥ä½œé‡
- é›¶é£é™©ï¼ˆä¸è§¦ç¢°ç°æœ‰ä»£ç ï¼‰

### åŠŸèƒ½å¯¹æ¯”

| åŠŸèƒ½ | å½“å‰çŠ¶æ€ | å¢å¼ºå | æ”¹è¿› |
|-----|---------|--------|------|
| å¯¼å‡ºæ ¼å¼ | 2ç§ï¼ˆCSV, JSONï¼‰ | 4ç§+å¯æ‰©å±• | +100% |
| å¯¼å‡ºæ–¹å¼ | ä»…å®¢æˆ·ç«¯ | å®¢æˆ·ç«¯+æœåŠ¡ç«¯ | æ”¯æŒå¤§æ•°æ® |
| è‡ªåŠ¨åŒ– | æ‰‹åŠ¨ç‚¹å‡» | Command ä¸€é”®å®Œæˆ | æ•ˆç‡+50% |
| æ™ºèƒ½äº¤äº’ | æ—  | AI å»ºè®®+NL è§¦å‘ | ç”¨æˆ·ä½“éªŒ++ |
| å†å²è®°å½• | æ—  | å®Œæ•´å†å²è·Ÿè¸ª | å¯å®¡è®¡ |
| ä»£ç å¤ç”¨ | é‡å¤å®ç° | ç»Ÿä¸€æœåŠ¡ | -60% é‡å¤ |

### ä»£ç è´¨é‡æŒ‡æ ‡

| æŒ‡æ ‡ | ä¹‹å‰ | ä¹‹å | æ”¹è¿› |
|------|------|------|------|
| å¯¼å‡ºä»£ç è¡Œæ•° | ~180 (Home.tsx) | ~1200 (å«åç«¯) | åŠŸèƒ½å®Œå¤‡ |
| ä»£ç é‡å¤ | 100% (show.tsxæœªå®ç°) | <5% | -95% |
| æ ¼å¼æ”¯æŒ | 2 | 4+ | +100% |
| å¯æ‰©å±•æ€§ | ä½ | é«˜ | ç¬¦åˆSOLID |
| æµ‹è¯•è¦†ç›– | 0% | ç›®æ ‡80% | +80% |

## å®ç°è®¡åˆ’

### âœ… Phase 0: å½“å‰çŠ¶æ€ï¼ˆå·²å®Œæˆï¼‰
- [x] Home.tsx å‰ç«¯ CSV/JSON å¯¼å‡º
- [x] åŸºæœ¬å¯¼å‡ºåŠŸèƒ½å¯ç”¨

### ğŸ¯ Phase 1: åç«¯å¯¼å‡ºåŸºç¡€è®¾æ–½ï¼ˆ3å¤©ï¼‰
- [ ] base.py - æŠ½è±¡åŸºç±»å’Œæ•°æ®ç»“æ„
- [ ] csv_exporter.py - CSV å¯¼å‡ºå™¨
- [ ] json_exporter.py - JSON å¯¼å‡ºå™¨
- [ ] registry.py - å¯¼å‡ºæ ¼å¼æ³¨å†Œè¡¨
- [ ] export_service.py - å¯¼å‡ºæœåŠ¡é—¨é¢

### ğŸ¯ Phase 2: æ‰©å±•å¯¼å‡ºæ ¼å¼ï¼ˆ2å¤©ï¼‰
- [ ] excel_exporter.py - Excel å¯¼å‡ºå™¨
- [ ] sql_exporter.py - SQL å¯¼å‡ºå™¨
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•

### ğŸ¯ Phase 3: Command åŠŸèƒ½ï¼ˆ2å¤©ï¼‰
- [ ] export_command.py - å¯¼å‡ºå‘½ä»¤
- [ ] API ç«¯ç‚¹ï¼š`/query-and-export`
- [ ] é›†æˆæµ‹è¯•

### ğŸ¯ Phase 4: æ™ºèƒ½äº¤äº’ï¼ˆ2å¤©ï¼‰
- [ ] export_suggestion.py - å¯¼å‡ºå»ºè®®æœåŠ¡
- [ ] API ç«¯ç‚¹ï¼š`/export/suggest`, `/export/parse-nl`
- [ ] ExportSuggestion.tsx - å‰ç«¯ç»„ä»¶

### ğŸ¯ Phase 5: å¯¼å‡ºå†å²ï¼ˆ1å¤©ï¼‰
- [ ] export.py - æ•°æ®æ¨¡å‹
- [ ] æ•°æ®åº“è¿ç§»
- [ ] API ç«¯ç‚¹ï¼š`/exports`ï¼ˆå†å²æŸ¥è¯¢ï¼‰

### ğŸ¯ Phase 6: å‰ç«¯é›†æˆï¼ˆ2å¤©ï¼‰
- [ ] exportService.ts - ç»Ÿä¸€å¯¼å‡ºæœåŠ¡
- [ ] æ›´æ–° Home.tsx - é›†æˆå¯¼å‡ºå»ºè®®
- [ ] æ›´æ–° show.tsx - è¿æ¥å¯¼å‡ºåŠŸèƒ½
- [ ] æ·»åŠ  Excel å¯¼å‡ºæŒ‰é’®

### ğŸ¯ Phase 7: æµ‹è¯•å’Œæ–‡æ¡£ï¼ˆ1å¤©ï¼‰
- [ ] å•å…ƒæµ‹è¯•ï¼ˆç›®æ ‡è¦†ç›–ç‡ 80%ï¼‰
- [ ] é›†æˆæµ‹è¯•
- [ ] API æ–‡æ¡£æ›´æ–°
- [ ] ç”¨æˆ·æŒ‡å—

**æ€»è®¡å·¥ä½œé‡ä¼°ç®—ï¼š13 å¤©**

## ä½¿ç”¨ç¤ºä¾‹

### 1. API è°ƒç”¨ç¤ºä¾‹

#### å¯¼å‡ºæŸ¥è¯¢ç»“æœ
```bash
# CSV å¯¼å‡º
curl -X POST http://localhost:8000/api/v1/dbs/mydb/export \
  -H "Content-Type: application/json" \
  -d '{
    "columns": [{"name": "id", "dataType": "integer"}],
    "rows": [{"id": 1}, {"id": 2}],
    "format": "csv"
  }' \
  --output export.csv

# Excel å¯¼å‡ºï¼ˆå¸¦é€‰é¡¹ï¼‰
curl -X POST http://localhost:8000/api/v1/dbs/mydb/export \
  -H "Content-Type: application/json" \
  -d '{
    "columns": [{"name": "id", "dataType": "integer"}],
    "rows": [{"id": 1}, {"id": 2}],
    "format": "excel",
    "options": {
      "sheet_name": "User Data",
      "include_headers": true
    }
  }' \
  --output export.xlsx
```

#### ä¸€é”®æŸ¥è¯¢å¹¶å¯¼å‡º
```bash
curl -X POST http://localhost:8000/api/v1/dbs/mydb/query-and-export \
  -H "Content-Type: application/json" \
  -d '{
    "sql": "SELECT * FROM users WHERE active = true LIMIT 1000",
    "format": "excel"
  }' \
  --output users.xlsx
```

#### è·å–å¯¼å‡ºå»ºè®®
```bash
curl -X POST http://localhost:8000/api/v1/dbs/mydb/export/suggest \
  -H "Content-Type: application/json" \
  -d '{
    "sql": "SELECT name, SUM(amount) FROM orders GROUP BY name",
    "columns": [{"name": "name", "dataType": "varchar"}],
    "rowCount": 500
  }'

# Response:
{
  "should_suggest": true,
  "suggested_format": "excel",
  "reason": "æŸ¥è¯¢è¿”å›äº†500è¡Œæ•°æ®ï¼Œæ£€æµ‹åˆ°èšåˆå‡½æ•°ï¼ŒExcelæ ¼å¼æ›´é€‚åˆæ•°æ®åˆ†æ",
  "prompt_text": "éœ€è¦å°†è¿™æ¬¡çš„æŸ¥è¯¢ç»“æœå¯¼å‡ºä¸º Excel æ–‡ä»¶å—ï¼Ÿ..."
}
```

### 2. å‰ç«¯ä½¿ç”¨ç¤ºä¾‹

```typescript
import { ExportService } from "../services/exportService";

// æœåŠ¡ç«¯å¯¼å‡ºï¼ˆæ¨èï¼‰
await ExportService.exportServerSide(
  queryResult.columns,
  queryResult.rows,
  "excel",
  "mydb"
);

// ä¸€é”®æŸ¥è¯¢å¹¶å¯¼å‡º
await ExportService.queryAndExport(
  "mydb",
  "SELECT * FROM users",
  "csv"
);

// è·å–æ™ºèƒ½å»ºè®®
const suggestion = await ExportService.getExportSuggestion(
  "mydb",
  sql,
  columns,
  rowCount
);

if (suggestion.shouldSuggest) {
  // æ˜¾ç¤ºå¯¼å‡ºå»ºè®®å¯¹è¯æ¡†
  showExportSuggestionModal();
}
```

### 3. Python è„šæœ¬ä½¿ç”¨ç¤ºä¾‹

```python
# å®šæ—¶å¯¼å‡ºè„šæœ¬
import asyncio
from app.commands.export_command import ExportCommand
from app.services.database_service import database_service
from app.services.export_service import export_service

async def daily_export():
    """æ¯æ—¥æ•°æ®å¯¼å‡º"""
    command = ExportCommand(database_service, export_service)

    result = await command.execute(
        db_type=DatabaseType.POSTGRESQL,
        db_name="production",
        db_url="postgresql://...",
        sql="SELECT * FROM daily_stats WHERE date = CURRENT_DATE",
        export_format=ExportFormat.EXCEL,
        export_options=ExportOptions(
            sheet_name="Daily Stats",
            include_headers=True
        )
    )

    print(f"Exported {result.row_count} rows to {result.file_name}")

# è¿è¡Œ
asyncio.run(daily_export())
```

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```python
# tests/unit/test_csv_exporter.py
import pytest
from app.export.csv_exporter import CSVExporter
from app.export.base import ExportOptions, ExportFormat

@pytest.mark.asyncio
async def test_csv_export_basic():
    exporter = CSVExporter()
    columns = [{"name": "id", "dataType": "integer"}]
    rows = [{"id": 1}, {"id": 2}]
    options = ExportOptions(format=ExportFormat.CSV)

    result = await exporter.export(columns, rows, options)

    assert result.row_count == 2
    assert result.file_name.endswith(".csv")
    assert b"id" in result.file_data  # åŒ…å«è¡¨å¤´
    assert b"1" in result.file_data

@pytest.mark.asyncio
async def test_csv_export_special_chars():
    """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†"""
    exporter = CSVExporter()
    columns = [{"name": "name", "dataType": "varchar"}]
    rows = [{"name": "Alice, Bob"}, {"name": 'John "Doe"'}]
    options = ExportOptions(format=ExportFormat.CSV)

    result = await exporter.export(columns, rows, options)

    # éªŒè¯å¼•å·è½¬ä¹‰
    assert b'"Alice, Bob"' in result.file_data
    assert b'John ""Doe""' in result.file_data
```

### 2. é›†æˆæµ‹è¯•

```python
# tests/integration/test_export_api.py
import pytest
from httpx import AsyncClient

@pytest.mark.asyncio
async def test_export_endpoint(client: AsyncClient):
    """æµ‹è¯•å¯¼å‡º API ç«¯ç‚¹"""
    response = await client.post(
        "/api/v1/dbs/testdb/export",
        json={
            "columns": [{"name": "id", "dataType": "integer"}],
            "rows": [{"id": 1}],
            "format": "csv"
        }
    )

    assert response.status_code == 200
    assert response.headers["content-type"] == "text/csv"
    assert "attachment" in response.headers["content-disposition"]

@pytest.mark.asyncio
async def test_query_and_export_endpoint(client: AsyncClient):
    """æµ‹è¯•ä¸€é”®æŸ¥è¯¢å¹¶å¯¼å‡º"""
    response = await client.post(
        "/api/v1/dbs/testdb/query-and-export",
        json={
            "sql": "SELECT * FROM users LIMIT 10",
            "format": "json"
        }
    )

    assert response.status_code == 200
    assert response.headers["content-type"] == "application/json"
```

### 3. æ€§èƒ½æµ‹è¯•

```python
# tests/performance/test_export_performance.py
import pytest
import time

@pytest.mark.asyncio
async def test_large_dataset_export():
    """æµ‹è¯•å¤§æ•°æ®é›†å¯¼å‡ºæ€§èƒ½"""
    exporter = CSVExporter()

    # ç”Ÿæˆ 100,000 è¡Œæ•°æ®
    columns = [{"name": f"col{i}", "dataType": "varchar"} for i in range(10)]
    rows = [{f"col{i}": f"value{j}" for i in range(10)} for j in range(100000)]

    start = time.time()
    result = await exporter.export(columns, rows, ExportOptions(format=ExportFormat.CSV))
    duration = time.time() - start

    assert duration < 5.0  # åº”åœ¨ 5 ç§’å†…å®Œæˆ
    assert result.row_count == 100000
```

## å®‰å…¨è€ƒè™‘

### 1. æ–‡ä»¶å¤§å°é™åˆ¶

```python
# app/export/base.py
MAX_EXPORT_ROWS = 1_000_000  # æœ€å¤§å¯¼å‡ºè¡Œæ•°
MAX_FILE_SIZE = 500 * 1024 * 1024  # 500 MB

class BaseExporter(ABC):
    def validate_options(self, options: ExportOptions) -> tuple[bool, Optional[str]]:
        if options.max_rows and options.max_rows > MAX_EXPORT_ROWS:
            return False, f"Cannot export more than {MAX_EXPORT_ROWS} rows"
        return True, None
```

### 2. æ–‡ä»¶åæ¸…ç†

```python
import re

def sanitize_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œé˜²æ­¢è·¯å¾„éå†æ”»å‡»"""
    # ç§»é™¤å±é™©å­—ç¬¦
    filename = re.sub(r'[^\w\-_\.]', '_', filename)
    # é™åˆ¶é•¿åº¦
    filename = filename[:200]
    return filename
```

### 3. ä¸´æ—¶æ–‡ä»¶æ¸…ç†

```python
# app/services/export_service.py
import tempfile
import atexit
import os

class ExportService:
    def __init__(self):
        self.temp_files = []
        atexit.register(self.cleanup_temp_files)

    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶å¯¼å‡ºæ–‡ä»¶"""
        for file_path in self.temp_files:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
            except Exception as e:
                logger.warning(f"Failed to cleanup temp file: {e}")
```

## æœªæ¥æ‰©å±•

### è½»æ¾æ·»åŠ æ–°å¯¼å‡ºæ ¼å¼

åªéœ€3æ­¥æ·»åŠ  Parquet/Avro ç­‰æ–°æ ¼å¼ï¼š

1. åˆ›å»ºå¯¼å‡ºå™¨ç±»ç»§æ‰¿ BaseExporter
2. å®ç°æŠ½è±¡æ–¹æ³•
3. æ³¨å†Œåˆ° export_registry

### å¯èƒ½çš„å¢å¼º

- **å‹ç¼©æ”¯æŒ**: è‡ªåŠ¨å‹ç¼©å¤§æ–‡ä»¶ï¼ˆ.zip, .gzï¼‰
- **åˆ†ç‰‡å¯¼å‡º**: è¶…å¤§æ•°æ®é›†åˆ†ç‰‡å¯¼å‡º
- **äº‘å­˜å‚¨**: ç›´æ¥å¯¼å‡ºåˆ° S3/Azure Blob
- **å®šæ—¶å¯¼å‡º**: Cron ä»»åŠ¡è°ƒåº¦
- **é‚®ä»¶å‘é€**: å¯¼å‡ºå®Œæˆåå‘é€é‚®ä»¶é€šçŸ¥
- **æƒé™æ§åˆ¶**: åŸºäºç”¨æˆ·è§’è‰²çš„å¯¼å‡ºæƒé™
- **å¯¼å‡ºæ¨¡æ¿**: é¢„å®šä¹‰çš„å¯¼å‡ºé…ç½®æ¨¡æ¿
- **å¢é‡å¯¼å‡º**: ä»…å¯¼å‡ºå¢é‡æ•°æ®

## ç»“è®º

æœ¬è®¾è®¡å®ç°äº†ä»¥ä¸‹ç›®æ ‡ï¼š

1. âœ… **å¤šæ ¼å¼æ”¯æŒ**: CSVã€JSONã€Excelã€SQLï¼Œå¯è½»æ¾æ‰©å±•
2. âœ… **è‡ªåŠ¨åŒ–æµç¨‹**: ExportCommand å®ç°æŸ¥è¯¢+å¯¼å‡ºä¸€é”®å®Œæˆ
3. âœ… **æ™ºèƒ½äº¤äº’**: AI é©±åŠ¨çš„å¯¼å‡ºå»ºè®®å’Œè‡ªç„¶è¯­è¨€è§¦å‘
4. âœ… **ç»Ÿä¸€æ¶æ„**: å‰åç«¯ååŒï¼Œæ”¯æŒå¤§æ•°æ®å’Œå†å²è®°å½•
5. âœ… **å®Œå…¨éµå¾ª SOLID åŸåˆ™**: é«˜å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§
6. âœ… **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**: æ™ºèƒ½å»ºè®®ã€è‡ªåŠ¨è§¦å‘ã€æ— ç¼é›†æˆ

æ–°æ¶æ„ä½¿å¾—ï¼š
- æ·»åŠ æ–°å¯¼å‡ºæ ¼å¼ä»…éœ€ 1 ä¸ªæ–‡ä»¶ + 2 è¡Œä»£ç 
- ä»£ç é‡å¤ç‡ä» 100% é™è‡³ <5%
- æ”¯æŒå®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯å¯¼å‡ºï¼Œé€‚åº”ä¸åŒæ•°æ®è§„æ¨¡
- æä¾›æ™ºèƒ½åŒ–çš„ç”¨æˆ·äº¤äº’ä½“éªŒ
- ä¸ºæœªæ¥åŠŸèƒ½æ‰©å±•å¥ å®šåšå®åŸºç¡€

è¿™æ¬¡å¢å¼ºä¸ºé¡¹ç›®çš„æ•°æ®å¯¼å‡ºèƒ½åŠ›æä¾›äº†ä¼ä¸šçº§çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶ä¿æŒäº†ä»£ç çš„ç®€æ´æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
